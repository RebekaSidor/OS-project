FROM eclipse-temurin:11-jdk

# Spark version
ENV SPARK_VERSION=3.4.2
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

# Required packages
RUN apt-get update && apt-get install -y curl python3 python3-pip procps && \
    rm -rf /var/lib/apt/lists/*

RUN pip3 install --break-system-packages pyspark matplotlib pandas

# Install Spark
RUN curl -L https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz \
    -o spark.tgz && \
    tar xzf spark.tgz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} ${SPARK_HOME} && \
    rm spark.tgz

# Spark config
COPY spark-defaults.conf $SPARK_HOME/conf/spark-defaults.conf
# This next step is optional, Spark will work without it as well
COPY spark-env.sh $SPARK_HOME/conf/spark-env.sh

# Start script
COPY start-spark.sh /opt/start-spark.sh
RUN chmod +x /opt/start-spark.sh

# Python job
COPY analysis_spark.py /app/analysis_spark.py

EXPOSE 8080 8081 6066 7077

WORKDIR /opt
CMD ["/opt/start-spark.sh"]